{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: JSAnimation in /home/xiaozhu/anaconda3/lib/python3.7/site-packages (0.1)\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: progressbar in /home/xiaozhu/anaconda3/lib/python3.7/site-packages (2.5)\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# install package for displaying animation\n",
    "!pip install JSAnimation\n",
    "!pip install progressbar\n",
    "\n",
    "\n",
    "# custom utilies for displaying animation, collecting rollouts and more\n",
    "from utils import pong_utils\n",
    "from PPO.ppo import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check which device is being used. \n",
    "# I recommend disabling gpu until you've made sure that the code runs\n",
    "device = pong_utils.device\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "import gym\n",
    "import time\n",
    "\n",
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "policy=Policy().to(device)\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show what a preprocessed image looks like\n",
    "env.reset()\n",
    "_, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _ = env.step(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3702a4fab9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpong_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# try to add the option \"preprocess=pong_utils.preprocess_single\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# to see what the agent sees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'policy' is not defined"
     ]
    }
   ],
   "source": [
    "pong_utils.play(env, policy, time=200) \n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "### PPO\n",
    "$\\frac{1}{T}\\sum^T_t \\min\\left\\{R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)},R_{t}^{\\rm future}{\\rm clip}_{\\epsilon}\\!\\left(\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}\\right)\\right\\}$\n",
    "\n",
    "the ${\\rm clip}_\\epsilon$ function is implemented in pytorch as ```torch.clamp(ratio, 1-epsilon, 1+epsilon)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)\n",
    "\n",
    "episode = 500\n",
    "\n",
    "# widget bar to display progress\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        L = -clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                                          epsilon=epsilon, beta=beta)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your policy!\n",
    "torch.save(policy, 'PPO.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
